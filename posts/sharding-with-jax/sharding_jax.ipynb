{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sharding with jax\n",
        "\n",
        "Hicham Randrianarivo\n",
        "\n",
        "# Sharding with jax\n",
        "\n",
        "[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/chicham/chicham.github.io/blob/gh-pages/posts/sharding-with-jax/sharding_jax.ipynb)\n",
        "\n",
        "## Links\n",
        "\n",
        "-   [Tutorial ICML\n",
        "    2022](https://sites.google.com/view/icml-2022-big-model/home)\n",
        "-   [Distributed arrays and automatic\n",
        "    parallelization](https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html)\n",
        "-   [https://github.com/google-research/big_vision](Big%20vision) the\n",
        "    idea of the sharding class\n",
        "\n",
        "## Pre-requisites\n",
        "\n",
        "-   Train a 8 layers model\n",
        "-   Generate random data cube"
      ],
      "id": "cc01d25e-1618-4f50-b009-5be0d02809a9"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install -r https://raw.githubusercontent.com/chicham/chicham.github.io/main/posts/sharding-with-jax/requirements.txt\n",
        "from jax.random import PRNGKey\n",
        "import jax.numpy as jnp\n",
        "\n",
        "import keras_core as K\n",
        "import datetime\n",
        "\n",
        "\n",
        "N_TRAIN = 8*2**(10+4)\n",
        "N_EVAL = 8*2**10\n",
        "\n",
        "key = PRNGKey(0)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = K.datasets.mnist.load_data()\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = jnp.expand_dims(x_train, -1\n",
        "x_test = jnp.expand_dims(x_test, -1)\n",
        "\n",
        "input_shape = 28, 28, 1\n",
        "\n",
        "model = K.Sequential(\n",
        "  [\n",
        "    K.layers.Flatten(input_shape),\n",
        "    K.layers.Dense(128, activation=\"relu\"),\n",
        "    K.layers.Dense(128, activation=\"relu\"),\n",
        "    K.layers.Dropout(rate=.5),\n",
        "    K.layers.Dense(128, activation=\"relu\"),\n",
        "    K.layers.Dense(128, activation=\"relu\"),\n",
        "    K.layers.Dropout(rate=.5),\n",
        "    K.layers.Dense(128, activation=\"relu\"),\n",
        "    K.layers.Dense(128, activation=\"relu\"),\n",
        "    K.layers.Dropout(rate=.5),\n",
        "    K.layers.Dense(128, activation=\"relu\"),\n",
        "    K.layers.Dense(10, activation=\"softmax\"),\n",
        "  ]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=K.optimizers.Adam(0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "id": "5c033ff5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Methods\n",
        "\n",
        "### Baseline"
      ],
      "id": "428bccbb-649a-475f-be34-0df90258a5e6"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "baseline_logs = \"logs/baseline/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "baseline_callback = K.callbacks.TensorBoard(\n",
        "  log_dir = baseline_logs,\n",
        "  histogram_freq = 1,\n",
        "  profile_batch = '500,520'\n",
        ")\n",
        "\n",
        "\n",
        "model.fit(\n",
        "  x_train,\n",
        "  y_train,\n",
        "  epochs=2,\n",
        "  validation_split=0.20,\n",
        "  callbacks = [baseline_callback]\n",
        ")"
      ],
      "id": "b2346801"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Data parallelism\n",
        "    -   Data parallelism with all reduce\n",
        "-   Model Parallelism\n",
        "    -   Device placement\n",
        "        -   issue: each modules must wait for the computation of the\n",
        "            previous one\n",
        "        -   Micro batches\n",
        "            -   GPipe\n",
        "            -   1F1B\n",
        "            -   Interleaved 1F1B (megatron)\n",
        "                -   Split layers between multiple devices\n",
        "        -   Async pipelines (wonâ€™t cover this)\n",
        "    -   Split parameters ( intra-op parallelism)\n",
        "        -   Megatron-LM\n",
        "        -   ZeRO"
      ],
      "id": "4d780401-d361-470a-813d-b1e8efcb4f92"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    }
  }
}