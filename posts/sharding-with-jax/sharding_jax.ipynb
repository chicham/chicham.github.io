{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sharding with jax\n",
        "\n",
        "Hicham Randrianarivo\n",
        "\n",
        "# Sharding with jax\n",
        "\n",
        "<a\n",
        "href=\"https://colab.research.google.com/github/chicham/chicham.github.io/blob/master/posts/sharding_jax/sharding_jax.ipnb\"\n",
        "data-fig-align=\"left\"><img\n",
        "src=\"https://colab.research.google.com/assets/colab-badge.svg\" /></a>\n",
        "\n",
        "## Links\n",
        "\n",
        "-   [Tutorial ICML\n",
        "    2022](https://sites.google.com/view/icml-2022-big-model/home)\n",
        "-   [Distributed arrays and automatic\n",
        "    parallelization](https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html)\n",
        "-   [https://github.com/google-research/big_vision](Big%20vision) the\n",
        "    idea of the sharding class\n",
        "\n",
        "## Pre-requisites\n",
        "\n",
        "-   Train a 8 layers model\n",
        "-   Generate random data cube\n",
        "\n",
        "## Methods\n",
        "\n",
        "### Baseline\n",
        "\n",
        "-   Data parallelism\n",
        "    -   Data parallelism with all reduce\n",
        "-   Model Parallelism\n",
        "    -   Device placement\n",
        "        -   issue: each modules must wait for the computation of the\n",
        "            previous one\n",
        "        -   Micro batches\n",
        "            -   GPipe\n",
        "            -   1F1B\n",
        "            -   Interleaved 1F1B (megatron)\n",
        "                -   Split layers between multiple devices\n",
        "        -   Async pipelines (wonâ€™t cover this)\n",
        "    -   Split parameters ( intra-op parallelism)\n",
        "        -   Megatron-LM\n",
        "        -   ZeRO"
      ],
      "id": "6097edd3-2b0b-4640-8e75-2050e0d07772"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    }
  }
}