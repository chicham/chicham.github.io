{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sharding with jax\n",
        "\n",
        "Hicham Randrianarivo\n",
        "\n",
        "# Sharding with jax\n",
        "\n",
        "[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/chicham/chicham.github.io/blob/gh-pages/posts/sharding-with-jax/sharding_jax.ipynb)\n",
        "\n",
        "## Links\n",
        "\n",
        "-   [Tutorial ICML\n",
        "    2022](https://sites.google.com/view/icml-2022-big-model/home)\n",
        "-   [Distributed arrays and automatic\n",
        "    parallelization](https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html)\n",
        "-   [https://github.com/google-research/big_vision](Big%20vision) the\n",
        "    idea of the sharding class\n",
        "\n",
        "## Pre-requisites\n",
        "\n",
        "-   Train a 8 layers model\n",
        "-   Generate random data cube"
      ],
      "id": "51a45d52-83e1-48ff-b352-f28bfc9115b3"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "```{python}\n",
        "from jax.random import PRNGKe\n",
        "import jax.numpy as jnp\n",
        "\n",
        "import keras_core as K\n",
        "import datetime\n",
        "\n",
        "\n",
        "N_TRAIN = 8*2**(10+4)\n",
        "N_EVAL = 8*2**10\n",
        "\n",
        "key = PRNGKey(0)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = K.datasets.mnist.load_data()\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = jnp.expand_dims(x_train, -1\n",
        "x_test = jnp.expand_dims(x_test, -1)\n",
        "\n",
        "input_shape = 28, 28, 1\n",
        "\n",
        "model = K.Sequential(\n",
        "  [\n",
        "    K.layers.Flatten(input_shape),\n",
        "    K.layers.Dense(128, activation=\"relu\"),\n",
        "    K.layers.Dense(128, activation=\"relu\"),\n",
        "    K.layers.Dropout(rate=.5),\n",
        "    K.layers.Dense(128, activation=\"relu\"),\n",
        "    K.layers.Dense(128, activation=\"relu\"),\n",
        "    K.layers.Dropout(rate=.5),\n",
        "    K.layers.Dense(128, activation=\"relu\"),\n",
        "    K.layers.Dense(128, activation=\"relu\"),\n",
        "    K.layers.Dropout(rate=.5),\n",
        "    K.layers.Dense(128, activation=\"relu\"),\n",
        "    K.layers.Dense(10, activation=\"softmax\"),\n",
        "  ]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=K.optimizers.Adam(0.001),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "```\n"
      ],
      "id": "893e7d9d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Methods\n",
        "\n",
        "### Baseline"
      ],
      "id": "8f20025f-493b-495a-aa11-2e401a3b01a3"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "```{python}\n",
        "baseline_logs = \"logs/baseline/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "baseline_callback = K.callbacks.TensorBoard(\n",
        "  log_dir = baseline_logs,\n",
        "  histogram_freq = 1,\n",
        "  profile_batch = '500,520'\n",
        ")\n",
        "\n",
        "\n",
        "model.fit(\n",
        "  x_train,\n",
        "  y_train,\n",
        "  epochs=2,\n",
        "  validation_split=0.20,\n",
        "  callbacks = [baseline_callback])\n",
        "```\n"
      ],
      "id": "521c192f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Data parallelism\n",
        "    -   Data parallelism with all reduce\n",
        "-   Model Parallelism\n",
        "    -   Device placement\n",
        "        -   issue: each modules must wait for the computation of the\n",
        "            previous one\n",
        "        -   Micro batches\n",
        "            -   GPipe\n",
        "            -   1F1B\n",
        "            -   Interleaved 1F1B (megatron)\n",
        "                -   Split layers between multiple devices\n",
        "        -   Async pipelines (wonâ€™t cover this)\n",
        "    -   Split parameters ( intra-op parallelism)\n",
        "        -   Megatron-LM\n",
        "        -   ZeRO"
      ],
      "id": "81ce1658-830f-4adf-aee3-e1ed890d7011"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  }
}