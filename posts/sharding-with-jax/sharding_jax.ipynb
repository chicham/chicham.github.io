{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a0523b7f",
   "metadata": {},
   "source": [
    "---\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "  ipynb: default\n",
    "title: Sharding with jax\n",
    "draft: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b21ccb",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Pre-requisites: Parallelism for deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a327879",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "# Utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39939d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "import jax\n",
    "from jax import random\n",
    "import jax.numpy as jnp\n",
    "import keras as K\n",
    "from pathlib import Path\n",
    "\n",
    "import tempfile\n",
    "import shutil\n",
    "# jax.distributed.initialize()\n",
    "\n",
    "N_TRAIN = 8 * 2 ** (10 + 4)\n",
    "N_EVAL = 8 * 2**10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "key = random.PRNGKey(0)\n",
    "\n",
    "print(\"Download dataset\")\n",
    "(x_train, y_train), (x_test, y_test) = K.datasets.mnist.load_data()\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = jnp.expand_dims(x_train, -1)\n",
    "x_test = jnp.expand_dims(x_test, -1)\n",
    "\n",
    "input_shape = 28, 28, 1\n",
    "\n",
    "print(\"Make model\")\n",
    "model = K.Sequential(\n",
    "    [\n",
    "        K.layers.Input(shape=input_shape),\n",
    "        K.layers.Flatten(),\n",
    "        K.layers.Dense(128, activation=\"relu\"),\n",
    "        K.layers.Dense(128, activation=\"relu\"),\n",
    "        K.layers.Dropout(rate=0.5),\n",
    "        K.layers.Dense(128, activation=\"relu\"),\n",
    "        K.layers.Dense(128, activation=\"relu\"),\n",
    "        K.layers.Dropout(rate=0.5),\n",
    "        K.layers.Dense(128, activation=\"relu\"),\n",
    "        K.layers.Dense(128, activation=\"relu\"),\n",
    "        K.layers.Dropout(rate=0.5),\n",
    "        K.layers.Dense(128, activation=\"relu\"),\n",
    "        K.layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()\n",
    "loss_fn = K.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = K.optimizers.Adam(3e-4)\n",
    "train_metric = K.metrics.CategoricalAccuracy()\n",
    "\n",
    "\n",
    "def compute_loss(trainable_variables, non_trainable_variables, metrics_variables, x, y):\n",
    "    y_pred, non_trainable_variables = model.stateless_call(\n",
    "        trainable_variables, non_trainable_variables, x\n",
    "    )\n",
    "    loss = loss_fn(y, y_pred)\n",
    "    metrics_variables = train_metric.stateless_update_state(\n",
    "        metrics_variables, y, y_pred\n",
    "    )\n",
    "    return loss, (non_trainable_variables, metrics_variables)\n",
    "\n",
    "\n",
    "grad_fn = jax.value_and_grad(compute_loss, has_aux=True)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def train_step(state, data):\n",
    "    (\n",
    "        trainable_variables,\n",
    "        non_trainable_variables,\n",
    "        optimizer_variables,\n",
    "        metric_variables,\n",
    "    ) = state\n",
    "    x, y = data\n",
    "\n",
    "    (loss, (non_trainable_variables, metric_variables)), grads = grad_fn(\n",
    "        trainable_variables, non_trainable_variables, metric_variables, x, y\n",
    "    )\n",
    "    trainable_variables, optimizer_variables = optimizer.stateless_apply(\n",
    "        optimizer_variables, grads, trainable_variables\n",
    "    )\n",
    "\n",
    "    return loss, (\n",
    "        trainable_variables,\n",
    "        non_trainable_variables,\n",
    "        optimizer_variables,\n",
    "        metric_variables,\n",
    "    )\n",
    "\n",
    "\n",
    "logs_dir = Path(\"logs/\").resolve()\n",
    "logs_dir.mkdir(exist_ok=True)\n",
    "\n",
    "trainable_variables = model.trainable_variables\n",
    "non_trainable_variables = model.non_trainable_variables\n",
    "\n",
    "optimizer.build(trainable_variables)\n",
    "optimizer_variables = optimizer.variables\n",
    "metrics_variables = train_metric.variables\n",
    "\n",
    "state = (\n",
    "    trainable_variables,\n",
    "    non_trainable_variables,\n",
    "    optimizer_variables,\n",
    "    metrics_variables,\n",
    ")\n",
    "\n",
    "x_train = x_train[2 * BATCH_SIZE :]\n",
    "y_train = y_train[2 * BATCH_SIZE :]\n",
    "\n",
    "\n",
    "def run(state, x_train, y_train):\n",
    "    acc_loss = 0\n",
    "    for step in range(0, x_train.shape[0], BATCH_SIZE):\n",
    "        data = x_train[step : step + BATCH_SIZE], y_train[step : step + BATCH_SIZE]\n",
    "        with jax.profiler.TraceAnnotation(\"train_step\"):\n",
    "            loss, state = train_step(state, data)\n",
    "            loss.block_until_ready()\n",
    "            acc_loss += loss\n",
    "        if step % 100 == 0:\n",
    "            *_, metrics_variables = state\n",
    "            for variable, value in zip(train_metric.variables, metrics_variables):\n",
    "                variable.assign(value)\n",
    "            print(f\"Acc: {train_metric.result()}\")\n",
    "            print(f\"Loss: {acc_loss / (step + 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe634bc",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Experiments\n",
    "## Baseline run on 1 device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6cc80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_dir = logs_dir / \"baseline\"\n",
    "\n",
    "if not baseline_dir.exists():\n",
    "    with tempfile.TemporaryDirectory(prefix=\"sharding_jax_\") as tmpdir:\n",
    "        with jax.profiler.trace(tmpdir):\n",
    "            run(state, x_train, y_train)\n",
    "        shutil.move(tmpdir, baseline_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189f312f",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Replicated"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
